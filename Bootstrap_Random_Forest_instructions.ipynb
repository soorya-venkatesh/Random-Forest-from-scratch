{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AjzGopb_YcKR"
   },
   "source": [
    "# Application of Bootstrap samples in Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZSCtDI6YcKT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2Y1Z1DoYcKZ"
   },
   "source": [
    " <li> Load the boston house dataset </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wBWRNKCDYcKb"
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable\n",
    "y=y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DTbK20-mWYHU",
    "outputId": "b473b251-a104-44df-f6c3-3427184c9042"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JJ_FwP7xYcKg"
   },
   "source": [
    "### Task: 1\n",
    "<font color='red'><b>Step 1 Creating samples: </b></font> Randomly create 30 samples from the whole boston data points.\n",
    "<ol>\n",
    "<li>Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points</li>\n",
    "<li>Ex: For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly consider we have selected [4, 5, 7, 8, 9, 3] now we will replciate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]</li>\n",
    "<li> we create 30 samples like this </li>\n",
    "<li> Note that as a part of the Bagging when you are taking the random samples make sure each of the sample will have                different set of columns</li>\n",
    "<li> Ex: assume we have 10 columns for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample [7, 9, 1, 4, 5, 6, 2] and so on...</li>\n",
    "<li> Make sure each sample will have atleast 3 feautres/columns/attributes</li>\n",
    "</ol>\n",
    "\n",
    "<font color='red'><b>Step 2 Building High Variance Models on each of the sample and finding train MSE value:</b></font> Build a DecisionTreeRegressor on each of the sample.\n",
    "<ol><li>Build a regression trees on each of 30 samples.</li>\n",
    "<li>computed the predicted values of each data point(506 data points) in your corpus.</li>\n",
    "<li> predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.</li>\n",
    "<li>Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$.</li>\n",
    "</ol>\n",
    "\n",
    "<font color='red'><b>Step 3 Calculating the OOB score :</b></font>\n",
    "<ol>\n",
    "<li>Computed the predicted values of each data point(506 data points) in your corpus.</li>\n",
    "<li>Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.</li>\n",
    "<li>Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$.</li>\n",
    "</ol>\n",
    "\n",
    "### Task: 2\n",
    "<pre>\n",
    "<font color='red'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
    "<ol>\n",
    "<li> Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
    "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
    "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
    "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
    "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
    "</ol>\n",
    "</pre>\n",
    "### Task: 3\n",
    "<pre>\n",
    "<font color='red'><b>Given a single query point predict the price of house.</b></font>\n",
    "\n",
    "<li>Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] Predict the house price for this point as mentioned in the step 2 of Task 1. </li>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://codereview.stackexchange.com/questions/193835/checking-a-one-dimensional-numpy-array-in-a-multidimensional-array-without-a-loo\n",
    "\n",
    "def check(test,array):\n",
    "    return any(np.array_equal(x, test) for x in array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/14262654/numpy-get-random-set-of-rows-from-2d-array\n",
    "\n",
    "\n",
    "#CREATE SAMPLES 30 TIMES WHERE EACH SAMPLE HAS 506 SAMPLES\n",
    "def createsample(x,y):\n",
    "    lx=[]\n",
    "    ly=[]\n",
    "    col=[]\n",
    "    \n",
    "    \n",
    "    for i in (range (30)):\n",
    "        #RANDOMLY SAMPLE 303 DATAPOINTS WITHOUT REPLCAEMENT FROM X AND Y AND STORE IT IN TEMP AND TEMP_Y\n",
    "        rowind=np.random.choice(x.shape[0], 303,replace=False)\n",
    "        colind=np.random.choice(x.shape[1],size=np.random.randint(low=3,high=13),replace=False)\n",
    "        temp=x[:,colind][rowind,:]\n",
    "        temp_y= y[rowind,:]\n",
    "\n",
    "        #RADOMLY SAMPLE 203 DATAPOINTS WITH REPLCAMENT FROM TEMP AND TEMP_Y AND STORE IT IN TEMP1 AND TEMP1_Y\n",
    "        rowind_replaced= np.random.choice(temp.shape[0], 203, replace=True)\n",
    "        temp1=temp[rowind_replaced,:]\n",
    "        temp1_y=temp_y[rowind_replaced,:]\n",
    "        \n",
    "        #CONCATENATE TEMP AND TEMP1 TO CREATE SAMPLE_X\n",
    "        #CONCATENATE TEMP_Y AND TEMP1_Y TO CREATE SAMPLE_Y\n",
    "        sample_x=np.vstack((temp,temp1))\n",
    "        sample_y=np.vstack((temp_y,temp1_y))\n",
    "        \n",
    "        lx.append(sample_x)\n",
    "        ly.append(sample_y)\n",
    "        col.append(colind)\n",
    "        \n",
    "    return(lx,ly,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_y(lx,x,col):\n",
    "\n",
    "    pred=[]\n",
    "    pred1=[]\n",
    "    \n",
    "    #FOR EVERY ith DATAPOINT IN WHOLE DATASET\n",
    "    for item in (x):\n",
    "        s=0 #SUM FOR MSE FOR WHOLE DATA\n",
    "        s1=0 #SUM FOR MSE FOR OOB POINTS\n",
    "        cnt=0 #KEEPINNG COUNT THE NUMBER OF POINTS THAT IS NOT PRESENT IN THE SAMPLED DATA\n",
    "\n",
    "        # FOR EVERY SAMPLED DATAPOINT\n",
    "        for j in range (0,len(lx)):\n",
    "            #FIT THE DATA\n",
    "            clf=DecisionTreeRegressor()\n",
    "            clf.fit(lx[j],ly[j])\n",
    "            t=item[col[j]]\n",
    "            \n",
    "            #CALCULATE YPRED FO WHOLE DATA\n",
    "            ypred=clf.predict(t.reshape(1,-1))\n",
    "            s=s+ypred\n",
    "            \n",
    "            #IF ith point NOT IN THE SAMPLED DATA\n",
    "            \n",
    "            if not check(t,lx[j]):\n",
    "                #CALCULATE YPRED FOR OOB\n",
    "                ypred1=clf.predict(t.reshape(1,-1))\n",
    "                #print(ypred)\n",
    "                s1=s1+ypred1\n",
    "                cnt+=1\n",
    "                \n",
    "\n",
    "        pred.append(s/30)#y_pred for whole data\n",
    "        pred1.append(s1/cnt)\n",
    "\n",
    "    \n",
    "    pred=np.array(pred)\n",
    "    pred1=np.array(pred1)\n",
    "    return(pred,pred1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for whole data 2.3207908794953225\n",
      "MSE for OOB pts 13.577434028426964\n"
     ]
    }
   ],
   "source": [
    "lx,ly,col=createsample(x,y)#FUNCTION CREATES 30 SAMPLES EACH OF LENGTH 506 AND IS SAMPLED AS MENTIONED IN THE INSTRUCTIONS\n",
    "\n",
    "pred,pred1=average_y(lx,x,col)#FUNCTION RETURNS THE AVEREAGE VALUE OF OF YPREDCITED FOR WHOLE DATASET AS WELL AS OOB PTS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "oob=mean_squared_error(pred1,y)\n",
    "mse=mean_squared_error(y,pred)\n",
    "\n",
    "print(\"MSE for whole data\",mse)\n",
    "print(\"MSE for OOB pts\",oob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55982d7961745fb88a751d5fe66ac46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=35), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oob=[]\n",
    "mse=[]\n",
    "for i in tqdm_notebook(range(0,35)):\n",
    "    \n",
    "    lx,ly,col=createsample(x,y)\n",
    "    pred,pred1=average_y(lx,x,col)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ob=mean_squared_error(pred1,y)\n",
    "    ms=mean_squared_error(y,pred)\n",
    "    \n",
    "    oob.append(ob)\n",
    "    mse.append(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=np.array(mse)\n",
    "oob=np.array(oob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 % CI for population mean of MSE for OOB pts is 2.414 - 2.637\n"
     ]
    }
   ],
   "source": [
    "sample_mean = mse.mean()\n",
    "sample_std =  mse.std()\n",
    "sample_size = len(mse)\n",
    "left_limit  = np.round(sample_mean - 2*(sample_std/np.sqrt(sample_size)), 3)\n",
    "right_limit = np.round(sample_mean + 2*(sample_std/np.sqrt(sample_size)), 3)\n",
    "\n",
    "print(\"95 % CI for population mean of MSE for OOB pts is\",left_limit,\"-\",right_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 % CI for population mean of oob for whole data is 14.028 - 14.711\n"
     ]
    }
   ],
   "source": [
    "sample_mean = oob.mean()\n",
    "sample_std =  oob.std()\n",
    "sample_size = len(oob)\n",
    "left_limit  = np.round(sample_mean - 2*(sample_std/np.sqrt(sample_size)), 3)\n",
    "right_limit = np.round(sample_mean + 2*(sample_std/np.sqrt(sample_size)), 3)\n",
    "\n",
    "print(\"95 % CI for population mean of oob for whole data is\",left_limit,\"-\",right_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lx,ly,col=createsample(x,y)\n",
    "xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60]\n",
    "xq=np.array(xq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predited house price for given query point is [19.62333333]\n"
     ]
    }
   ],
   "source": [
    "s=0\n",
    "\n",
    "for j in range (0,len(lx)):\n",
    "    clf=DecisionTreeRegressor()\n",
    "    clf.fit(lx[j],ly[j])\n",
    "    t=xq[col[j]]\n",
    "\n",
    "    ypred=clf.predict(t.reshape(1,-1))\n",
    "    s=s+ypred\n",
    "    \n",
    "print(\"the predited house price for given query point is\",s/30)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bootstrap_Random_Forest_instructions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
